{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
    "\n",
    "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "#!pip3 -qq install torch==0.4.1\n",
    "#!pip3 -qq install bokeh==0.13.0\n",
    "#!pip3 -qq install gensim==3.6.0\n",
    "#!pip3 -qq install nltk\n",
    "#!pip3 -qq install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Mikhail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Mikhail\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QstS4NO0L97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTai8Ta0lgwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCjwwDs6Zq9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'NUM', 'ADP', 'VERB', 'DET', 'PRT', 'ADJ', 'CONJ', 'X', 'NOUN', 'ADV', '.', 'PRON'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URC1B2nvPGFt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rWmSToIaeAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjz_Rk0bbMyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XCuxEBVbOY_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:  \n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4XsRII5kW5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4), (32, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=word_emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=word_emb_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count, proj_size=tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbrxsZ2mehWB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13043478260869565\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "\n",
    "def compute_accuracy(predictions, targets):\n",
    "    _, indices = torch.max(predictions, 2)\n",
    "    mask = targets > 0\n",
    "    correct_count = torch.sum(indices[mask] == targets[mask]).item()\n",
    "    total_count = torch.sum(mask).item()\n",
    "    return float(correct_count), float(total_count)\n",
    "\n",
    "correct_count, total_count = compute_accuracy(logits, y_batch)\n",
    "print(correct_count / total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMUyUm1hgpe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.9794, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss(predictions, targets, criterion=nn.CrossEntropyLoss(ignore_index=0)):\n",
    "    seq_size = len(predictions)\n",
    "    loss = 0\n",
    "    for i in range(seq_size):\n",
    "        loss += criterion(predictions[i], targets[i])\n",
    "    return loss\n",
    "\n",
    "print(compute_loss(logits, y_batch, criterion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисления в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = compute_loss(logits, y_batch, criterion=criterion)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                cur_correct_count, cur_sum_count = compute_accuracy(logits, y_batch)\n",
    "\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 30] Train: Loss = 52.47993, Accuracy = 72.32%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.05it/s]\n",
      "[1 / 30]   Val: Loss = 45.16084, Accuracy = 83.25%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 86.90it/s]\n",
      "[2 / 30] Train: Loss = 24.33868, Accuracy = 86.46%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.28it/s]\n",
      "[2 / 30]   Val: Loss = 29.19033, Accuracy = 89.06%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.09it/s]\n",
      "[3 / 30] Train: Loss = 16.19493, Accuracy = 91.03%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 53.21it/s]\n",
      "[3 / 30]   Val: Loss = 22.85555, Accuracy = 92.34%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.50it/s]\n",
      "[4 / 30] Train: Loss = 11.05025, Accuracy = 93.58%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.97it/s]\n",
      "[4 / 30]   Val: Loss = 18.41634, Accuracy = 93.82%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 86.32it/s]\n",
      "[5 / 30] Train: Loss = 7.94764, Accuracy = 95.04%: 100%|███████████████████████████████████████████████████| 572/572 [00:10<00:00, 53.07it/s]\n",
      "[5 / 30]   Val: Loss = 16.23935, Accuracy = 94.90%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 85.76it/s]\n",
      "[6 / 30] Train: Loss = 6.14628, Accuracy = 95.92%: 100%|███████████████████████████████████████████████████| 572/572 [00:10<00:00, 53.01it/s]\n",
      "[6 / 30]   Val: Loss = 15.96152, Accuracy = 95.08%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 85.20it/s]\n",
      "[7 / 30] Train: Loss = 5.10896, Accuracy = 96.43%: 100%|███████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.72it/s]\n",
      "[7 / 30]   Val: Loss = 13.74108, Accuracy = 95.40%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.47it/s]\n",
      "[8 / 30] Train: Loss = 4.46789, Accuracy = 96.77%: 100%|███████████████████████████████████████████████████| 572/572 [00:10<00:00, 53.09it/s]\n",
      "[8 / 30]   Val: Loss = 14.08187, Accuracy = 95.55%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.64it/s]\n",
      "[9 / 30] Train: Loss = 4.16413, Accuracy = 96.97%: 100%|███████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.65it/s]\n",
      "[9 / 30]   Val: Loss = 13.48728, Accuracy = 95.55%: 100%|████████████████████████████████████████████████████| 13/13 [00:00<00:00, 90.52it/s]\n",
      "[10 / 30] Train: Loss = 3.78247, Accuracy = 97.15%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.54it/s]\n",
      "[10 / 30]   Val: Loss = 14.25213, Accuracy = 95.46%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 86.61it/s]\n",
      "[11 / 30] Train: Loss = 3.56452, Accuracy = 97.26%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.64it/s]\n",
      "[11 / 30]   Val: Loss = 13.43671, Accuracy = 95.69%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.48it/s]\n",
      "[12 / 30] Train: Loss = 3.37253, Accuracy = 97.37%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.60it/s]\n",
      "[12 / 30]   Val: Loss = 14.50704, Accuracy = 95.68%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.64it/s]\n",
      "[13 / 30] Train: Loss = 3.16963, Accuracy = 97.50%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.26it/s]\n",
      "[13 / 30]   Val: Loss = 13.78098, Accuracy = 95.58%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.48it/s]\n",
      "[14 / 30] Train: Loss = 3.00012, Accuracy = 97.57%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.83it/s]\n",
      "[14 / 30]   Val: Loss = 13.39770, Accuracy = 95.64%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 86.31it/s]\n",
      "[15 / 30] Train: Loss = 2.92853, Accuracy = 97.63%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.62it/s]\n",
      "[15 / 30]   Val: Loss = 13.90031, Accuracy = 95.67%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 86.32it/s]\n",
      "[16 / 30] Train: Loss = 2.77848, Accuracy = 97.73%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.58it/s]\n",
      "[16 / 30]   Val: Loss = 16.75198, Accuracy = 95.72%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 83.56it/s]\n",
      "[17 / 30] Train: Loss = 2.67083, Accuracy = 97.78%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.66it/s]\n",
      "[17 / 30]   Val: Loss = 16.90340, Accuracy = 95.56%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 76.23it/s]\n",
      "[18 / 30] Train: Loss = 2.51541, Accuracy = 97.86%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.40it/s]\n",
      "[18 / 30]   Val: Loss = 14.66630, Accuracy = 95.57%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 85.20it/s]\n",
      "[19 / 30] Train: Loss = 2.48529, Accuracy = 97.88%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.66it/s]\n",
      "[19 / 30]   Val: Loss = 16.44470, Accuracy = 95.65%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.64it/s]\n",
      "[20 / 30] Train: Loss = 2.41473, Accuracy = 97.94%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.57it/s]\n",
      "[20 / 30]   Val: Loss = 16.31340, Accuracy = 95.66%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.36it/s]\n",
      "[21 / 30] Train: Loss = 2.30389, Accuracy = 98.02%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.65it/s]\n",
      "[21 / 30]   Val: Loss = 16.19021, Accuracy = 95.54%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 83.56it/s]\n",
      "[22 / 30] Train: Loss = 2.26950, Accuracy = 98.03%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 53.06it/s]\n",
      "[22 / 30]   Val: Loss = 15.05285, Accuracy = 95.61%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.67it/s]\n",
      "[23 / 30] Train: Loss = 2.16193, Accuracy = 98.12%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.68it/s]\n",
      "[23 / 30]   Val: Loss = 15.79978, Accuracy = 95.60%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.50it/s]\n",
      "[24 / 30] Train: Loss = 2.13037, Accuracy = 98.14%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.52it/s]\n",
      "[24 / 30]   Val: Loss = 16.37540, Accuracy = 95.66%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 83.56it/s]\n",
      "[25 / 30] Train: Loss = 1.96436, Accuracy = 98.24%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.57it/s]\n",
      "[25 / 30]   Val: Loss = 14.73003, Accuracy = 95.71%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.67it/s]\n",
      "[26 / 30] Train: Loss = 2.19090, Accuracy = 98.10%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.72it/s]\n",
      "[26 / 30]   Val: Loss = 15.04543, Accuracy = 95.59%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 89.28it/s]\n",
      "[27 / 30] Train: Loss = 1.96711, Accuracy = 98.23%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.70it/s]\n",
      "[27 / 30]   Val: Loss = 14.99884, Accuracy = 95.51%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.47it/s]\n",
      "[28 / 30] Train: Loss = 1.93241, Accuracy = 98.29%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.51it/s]\n",
      "[28 / 30]   Val: Loss = 17.29684, Accuracy = 95.69%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.49it/s]\n",
      "[29 / 30] Train: Loss = 1.77562, Accuracy = 98.37%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[29 / 30]   Val: Loss = 18.05778, Accuracy = 95.64%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.50it/s]\n",
      "[30 / 30] Train: Loss = 1.89917, Accuracy = 98.31%: 100%|██████████████████████████████████████████████████| 572/572 [00:10<00:00, 52.84it/s]\n",
      "[30 / 30]   Val: Loss = 17.85698, Accuracy = 95.64%: 100%|███████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=1e-3)\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=30,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98wr38_rw55D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: Loss = 9.97285, Accuracy = 95.73%: 100%|████████████████████████████████████████████████████████████| 224/224 [00:01<00:00, 151.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.9572656634615053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = do_epoch(model, criterion, (X_test, y_test), 64, None, 'Test:')\n",
    "print(f'Test accuracy:{test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZpY_Q1xZ18h"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsCstxiO03oT"
   },
   "outputs": [],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.vocab:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        <create me>\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        <use me>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBtI6BDE-Fc7"
   },
   "outputs": [],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
    "\n",
    "Добейтесь качества лучше прошлых моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPUuAPGhEGVR"
   },
   "outputs": [],
   "source": [
    "<calc test accuracy>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
